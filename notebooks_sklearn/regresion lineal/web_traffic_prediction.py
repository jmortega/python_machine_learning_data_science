# -*- coding: utf-8 -*-
"""web_traffic_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rBnw6OwWYXo_QA9oyja7ML-4OmvDbfyT

## Leer datos del fichero csv
"""

import numpy as np

data = np.loadtxt('https://raw.githubusercontent.com/jmortega/python_machine_learning_data_science/master/notebooks_sklearn/regresion%20lineal/web_traffic.tsv', delimiter='\t')

print(data.shape)

print(data[:10])

"""## Preparamos los datos"""

#tenemos coordenadas x,y
#una columna para las x y otra para las y
x = data[:, 0]
y = data[:, 1]

#eliminamos elementos nulos
x = x[~np.isnan(y)]
y = y[~np.isnan(y)]

"""## Gráfico de la evolución del tráfico en el último mes"""

import matplotlib.pyplot as plot

plot.figure(figsize=(12,6))
plot.scatter(x, y)
plot.title("Web traffic over the last month")
plot.xlabel("Time")
plot.ylabel("Hits/hour")
plot.xticks([w*7*24 for w in range(10)], ['week %i'%w for w in range(10)]) #pintamos week
plot.autoscale(tight=True)
plot.grid()
plot.show()

"""## Seleccionar nuestro modelo de regresión lineal"""

train = x[::, np.newaxis]
target = y.copy()

from sklearn.linear_model import LinearRegression
linear = LinearRegression()
linear.fit(train, target)

print("Puntación modelo lineal: ", linear.score(train, target))

from sklearn.model_selection import train_test_split

# Dividir los datos en conjuntos de entrenamiento / prueba 
x_train, x_test, y_train, y_test = train_test_split(train, target)

# Entrenar el modelo usando los conjuntos de entrenamiento
linear.fit(x_train, y_train)

# Puntuación de la varianza: 1 es la predicción perfecta 
puntuacion = linear.score(x_test, y_test)
print('Puntuacion:',puntuacion)

plot.figure(figsize=(12,6))
plot.scatter(x, y)
plot.title("Web traffic over the last month")
plot.xlabel("Time")
plot.ylabel("Hits/hour")
plot.xticks([w*7*24 for w in range(10)], ['week %i'%w for w in range(10)])
plot.autoscale(tight=True)
plot.grid()
plot.plot(train, linear.predict(train), color="red",linewidth=4)
plot.plot(x_test, linear.predict(x_test), color='orange', linewidth=3)
plot.show()

##Comprobar otros modelos que nos puedan dar una mejor aproximación de los datos
## LinearRegression 
from sklearn.linear_model import LinearRegression
linear = LinearRegression()
train = x[::, np.newaxis]
target = y.copy()
linear.fit(train, target)

print("Linear Model : ", linear.score(train, target))

## RandomForest
from sklearn.ensemble import RandomForestRegressor
random = RandomForestRegressor()
train = x[::, np.newaxis]
target = y.copy()
random.fit(train, target)
print("RandomForest Model : ", random.score(train, target))

## Polynomial degree
from sklearn.linear_model import Ridge
import numpy as np

ridge = Ridge()
rtrain = np.vander(x, 4 + 1)
target = y.copy()

ridge.fit(rtrain, target)

print("RidgeRegression Model : ", ridge.score(rtrain, target))

plot.figure(figsize=(12, 6))
plot.scatter(train, target)
#Linear
plot.plot(train, linear.predict(train),color="red", linewidth=4)

#RandomForest
plot.plot(train, random.predict(train),color="green", linewidth=4)

#Ridge
plot.plot(train, ridge.predict(rtrain),color="orange", linewidth=4)

plot.legend(["Linear", "RandomForest", "RidgeRegression"], loc="upper left")


plot.ylim(ymax=5000, ymin=500)

plot.show()

"""## Cross validation"""

from sklearn.model_selection import cross_validate as cv
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score

def split_data(X_data, y_data):
    """ Split the dataset in train and test """
    return train_test_split(X_data, y_data, test_size=0.1, random_state=0)

X_train, X_test, y_train, y_test = split_data(train, target)
#Linear
linear.fit(X_train, y_train)
print("Linear Model Score : ", linear.score(X_test, y_test))
scores_linear = cross_val_score(linear, X_test, y_test)
print("Linear Model Score mean : ", scores_linear.mean())

#Random
random.fit(X_train, y_train)
print("RandomForest Model Score : ", random.score(X_test, y_test))
scores_random = cross_val_score(random, X_test, y_test)
print("RandomForest Model Score mean : ", scores_random.mean())

#RidgeRegression
rtrain = np.vander(X_train[::, 0], 4 + 1)
rtest = np.vander(X_test[::, 0], 4 + 1)
ridge.fit(rtrain, y_train)
print("RidgeRegression Model Score: ", ridge.score(rtest, y_test))
scores_ridge = cross_val_score(linear, rtest, y_test)
print("RidgeRegression Model Score mean : ", scores_ridge.mean())